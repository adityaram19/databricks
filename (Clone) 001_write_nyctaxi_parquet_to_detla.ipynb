{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "93921291-d2b1-4e70-b52b-b761e1800298",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%python\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "# Create a Spark session with the desired configurations\n",
    "#spark = SparkSession.builder \\\n",
    "#    .appName(\"MyApp\") \\\n",
    "#   .config(\"spark.executor.memory\", \"8g\") \\\n",
    "#   .config(\"spark.executor.memoryOverhead\", \"4g\") \\\n",
    "#   .getOrCreate()\n",
    "\n",
    "# Define the path to the Parquet file in the volume\n",
    "parquet_file_path = \"/Volumes/dbrgstgnc1/testdb/bronze/yellow_tripdata_2025-01.parquet\"\n",
    "\n",
    "# Read the Parquet file into a DataFrame\n",
    "df = spark.read.parquet(parquet_file_path)\n",
    "\n",
    "# Define the target Delta table location or name\n",
    "delta_table_name = \"dbrgstgnc1.testdb.bronze_nyctaxi\"\n",
    "\n",
    "# Write the DataFrame to a Delta table\n",
    "df.write.format(\"delta\").mode(\"overwrite\").saveAsTable(delta_table_name)\n",
    "\n",
    "# Optional: Verify the table was created\n",
    "#display(spark.sql(f\"SELECT * FROM {delta_table_name} LIMIT 10\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "7923e6e1-1612-4f13-9398-f0ba11501d58",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%python\n",
    "import dlt\n",
    "\n",
    "# Retrieve the bronze table's storage path\n",
    "bronze_location = spark.sql(\"DESCRIBE TABLE EXTENDED dbrgstgnc1.testdb.bronze_nyctaxi\").filter(\"col_name = 'Location'\").select(\"data_type\").first()[0]\n",
    "\n",
    "# Define the silver table as a DLT streaming table\n",
    "@dlt.table(name=\"silver_nyctaxi\")\n",
    "def silver_nyctaxi():\n",
    "    return spark.readStream.format(\"delta\").load(bronze_location)"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "2"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "(Clone) 001_write_nyctaxi_parquet_to_detla",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
